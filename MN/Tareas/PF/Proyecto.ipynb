{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Proyecto final\n",
    "\n",
    "Proyecto final de __Metodos Numericos__ del curso impartido en _Ago - Dic 2020_.\n",
    "\n",
    "# Redes Neuronales \"feedforward\"\n",
    "\n",
    "__Benjamin Rivera__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Historia de las redes neuronales\n",
    "\n",
    "#### 1958 - Perceptron\n",
    "Frank Rosenblatt \\\n",
    " <img src=\"assets/Perceptron.jpg\" alt=\"Perceptron\" width=\"500\"> \n",
    " \n",
    " - Concepto de _pesos_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1965 - Perceptron multicapa\n",
    "\n",
    "<img src=\"assets/perceptron-multicapa.png\" alt=\"Perceptron multicapa\" width=\"500\">\n",
    "\n",
    " - Umbrales fijos\n",
    " - Valores binarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1980 - Aprendizaje automatico\n",
    "\n",
    "<img src=\"assets/sigmoide.webp\" alt=\"sigmoide\" width=\"500\">\n",
    "\n",
    "<img src=\"assets/forwardd.png\" alt=\"Flecha adleante\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1986 – Backpropagation\n",
    "\n",
    "<img src=\"assets/backpropagation.png\" alt=\"backpropagation\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Modernidad\n",
    "\n",
    "- 1989 Redes Neuronales Convolucionales\n",
    "\n",
    "<img src=\"assets/CNN_ex.png\" alt=\"convolutional NN\" width=\"500\">\n",
    "\n",
    "- 1997 Long Short Term Memory (LSTM) y Redes Neuronales Recurrentes\n",
    "\n",
    "<img src=\"assets/LSTM_cell.svg.png\" alt=\"lstm\" width=\"500\">\n",
    "\n",
    "<img src=\"assets/RNN.jpg\" alt=\"lstm\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Era de hielo\n",
    "\n",
    "<img src=\"assets/hielo.jpg\" alt=\"lstm\" width=\"500\" height=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Deep Learning\n",
    "\n",
    "- Transformers\n",
    "- Deepe Learning\n",
    "- Autoencoders\n",
    "- Redes Adversarias\n",
    "- Restricted Boltzmann Machines (🤔)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Clasificacion de las redes neuronales\n",
    "\n",
    "#### Por capa\n",
    " - Monocapa (red de Hopfield)\n",
    " - Multicapa\n",
    " \n",
    "#### Por topologia\n",
    " - Feedforward\n",
    " - Recurrente (LSTM)\n",
    " - Convolucionales\n",
    " \n",
    "#### Por tipo de entrenamiento\n",
    " - Por iluminacion divina (Estocastico o matematico)\n",
    " - Aprendizaje supervisado (Backpropagation)\n",
    " - Aprendizaje no supervisado (Redes adversarias)\n",
    " - Aprendizaje por refuerzo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## En este trabajo ...\n",
    "\n",
    "Se tratara de implementar una red neuronal feedforward con una estrategia de aprendizaje de _backpropagation_; por lo que trabajaremos en un ambiente de _entrenamiento supervisado_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Perceptrom\n",
    "\n",
    "$$ \\sum_{i=1}^{i=q} w_i * p_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Back propagation\n",
    "\n",
    " 1. Identificacion de la diferencia entre el estimulo y la aproximacion de la red\n",
    " 2. actualizacion de los pesos por el porcentaje del gradiente.\n",
    " \n",
    "Para el calculo de diferencias y gradiente\n",
    "\n",
    "```python\n",
    "    for l in range(len(a) - 2, 0, -1): \n",
    "        deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "```\n",
    "backpropagation\n",
    "```python\n",
    "    for i in range(len(self.weights)):\n",
    "        layer = np.atleast_2d(a[i])\n",
    "        delta = np.atleast_2d(deltas[i])\n",
    "        self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementacion\n",
    "\n",
    "Para la implementacion de este proyecto unicmanete se usara la libreria `numpy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Mejores alternativas\n",
    " - Keras\n",
    " - PyTorch\n",
    " - TensorFlow\n",
    " - scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Funciones de Activacion \n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def identity_derivada(x):\n",
    "    return 1\n",
    "\n",
    "def relu(x):\n",
    "    return 0 if x <= 0 else x\n",
    "\n",
    "def relu_derivada(x):\n",
    "    # Simplificacion para evitar errores.\n",
    "    return 0 if x <= 0 else 1\n",
    "\n",
    "def step(x):\n",
    "    return 0 if x < 0 else 1\n",
    "\n",
    "def step_derivada(x):\n",
    "    # Simplificacion para evitar errores.\n",
    "    return 0\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivada(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivada(x):\n",
    "    return 1.0 - x**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\" Clase para generalizar redes neuronales feedforward.\n",
    "    \n",
    "    Esta clase tiene como objetivo la generalizacion de las redes neurona_\n",
    "    les feedforward. Esta generalizacion no permite hacer modificaciones \n",
    "    a la estructura estandar donde todos los nodos (a exepcion de los de \n",
    "    salida) se comportan como perceptrones conectados a las siguientes \n",
    "    capas.\n",
    "    \n",
    "    Se tiene un unico constructor que inicializa todo como se pide\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, activation='tanh', w_range = (-1,1)):\n",
    "        # Verificacion de datos de entrada\n",
    "        if activation not in ['sigmoid', 'tanh', 'relu', 'step']:\n",
    "            raise Exception(\"Funcion de activacion no reconocida. \")\n",
    "        if w_range[0] >= w_range[1]:\n",
    "            raise Exception(\"Error en el rango de los pesos. \")\n",
    "        \n",
    "        # Seleccion de funcion de activacion\n",
    "        if activation == 'relu':\n",
    "            self.activation = relu\n",
    "            self.activation_prime = relu_derivada\n",
    "        elif activation == 'step':\n",
    "            self.activaition = step\n",
    "            self.activation_prime = step_derivada\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = sigmoid\n",
    "            self.activation_prime = sigmoid_derivada\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_prime = tanh_derivada\n",
    "        elif activaition == 'identity':\n",
    "            self.activation = identity\n",
    "            self.activation_prime = identity_derivada\n",
    "\n",
    "        # Inicializacion de pesos\n",
    "        self.weights = []\n",
    "        self.deltas = []\n",
    "        # valores aleatorios a pesos de entrada y capa oculta\n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = np.random.uniform(w_range[0], w_range[1], (layers[i-1] + 1, layers[i] + 1))\n",
    "            self.weights.append(r)\n",
    "        # valores aleatorios a capa de salida\n",
    "        r = np.random.uniform(w_range[0], w_range[1], (layers[i] + 1, layers[i+1]))\n",
    "        self.weights.append(r)\n",
    "\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.1, epochs=100000):\n",
    "        \"\"\" Funcion para realizar la aproximacion del modelo a los datos dados.\n",
    "        \n",
    "        Esta funcion trata de ajustar los pesos de la red (backpropagation) para\n",
    "        que se ajuste a los datos dados. Permite que se ajuste el \"ratio de \n",
    "        aprendizaje\" y la cantidad de iteraciones para el entrenamiento.\n",
    "        \n",
    "        Input:\n",
    "            X := Datos de la capa de entrada\n",
    "            y := Datos esperados en la capa de salida\n",
    "            learning_rate := Ratio de aprendizaje del modelo\n",
    "            epochs := Cantidad de iteraciones para el modelo\n",
    "        \"\"\"\n",
    "\n",
    "        # Agregacion de bias a capa de entrada\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "        \n",
    "        print(X)\n",
    "        raise Exception(\"Fin de prueba\")\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "\n",
    "            # Calculo del error en el modelo\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "            \n",
    "            # Calculamos los deltas\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "            self.deltas.append(deltas)\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 5000 == 0: print('epochs:', k)\n",
    "\n",
    "    def evaluate(self, x):\n",
    "        \"\"\" Funcion para evaluar una entrada en la red. \"\"\"\n",
    "        ones = np.atleast_2d(np.ones(x.shape[0]))\n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)), axis=0)\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "            \n",
    "    def set_weights(self, w):\n",
    "        \"\"\" Funcion establecer ciertos pesos. \"\"\"\n",
    "        try:\n",
    "            if w.shape == self.weights.shape:\n",
    "                self.weights = w\n",
    "        except AttributeError as e:\n",
    "            print(\"Los pesos se mantienen. \")\n",
    "            print(e)\n",
    "    \n",
    "    # Getters\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def get_deltas(self):\n",
    "        return self.deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def fast_training(X, y, hiden_layers=[3], epochs=15000, learning_rate=0.02, activation='tanh'):\n",
    "    \"\"\" Implementacion simplificada. \"\"\"\n",
    "    layers = [len(X[0]), len(y[0])]\n",
    "    for lay in hiden_layers:\n",
    "        layers.insert(-1, lay)\n",
    "\n",
    "    nn = NeuralNetwork(layers, activation=activation)\n",
    "    nn.fit(X, y, learning_rate=learning_rate, epochs=epochs)\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        print(\"X:\", X[i], \"y:\", y[i], \"\\n\\tAproximacion: \", nn.evaluate(X[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejemplos\n",
    "\n",
    " - Compuerta logica NOT\n",
    " - Compuerta logica AND\n",
    " - Compuerta logica OR\n",
    " - Compuerta logica XOR - Compuerta logica AND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0],\n",
    "              [1]])\n",
    "y = np.array([[1], \n",
    "              [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 1.]]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Fin de prueba",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c001b8d8b2f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfast_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-019b2c92f72a>\u001b[0m in \u001b[0;36mfast_training\u001b[0;34m(X, y, hiden_layers, epochs, learning_rate, activation)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-64b01c89f3e7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fin de prueba\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Fin de prueba"
     ]
    }
   ],
   "source": [
    "fast_training(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "X: [0] y: [1] \n",
      "\tAproximacion:  [0.95406978]\n",
      "X: [1] y: [0] \n",
      "\tAproximacion:  [0.00098776]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y, epochs=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "epochs: 10000\n",
      "epochs: 15000\n",
      "epochs: 20000\n",
      "epochs: 25000\n",
      "X: [0] y: [1] \n",
      "\tAproximacion:  [0.98385756]\n",
      "X: [1] y: [0] \n",
      "\tAproximacion:  [0.00014997]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y, epochs=25001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### And"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# And\n",
    "X = np.array([[0, 1],\n",
    "              [0, 0],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    " \n",
    "y = np.array([[0],\n",
    "              [0],\n",
    "              [0],\n",
    "              [1]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "epochs: 10000\n",
      "X: [0 1] y: [0] \n",
      "\tAproximacion:  [0.0011221]\n",
      "X: [0 0] y: [0] \n",
      "\tAproximacion:  [-0.00148757]\n",
      "X: [1 0] y: [0] \n",
      "\tAproximacion:  [0.00260917]\n",
      "X: [1 1] y: [1] \n",
      "\tAproximacion:  [0.96141139]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "X: [0 1] y: [0] \n",
      "\tAproximacion:  [0.07204406]\n",
      "X: [0 0] y: [0] \n",
      "\tAproximacion:  [-0.07873938]\n",
      "X: [1 0] y: [0] \n",
      "\tAproximacion:  [0.04653255]\n",
      "X: [1 1] y: [1] \n",
      "\tAproximacion:  [0.78034912]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y, epochs=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "epochs: 10000\n",
      "epochs: 15000\n",
      "epochs: 20000\n",
      "epochs: 25000\n",
      "epochs: 30000\n",
      "epochs: 35000\n",
      "epochs: 40000\n",
      "epochs: 45000\n",
      "epochs: 50000\n",
      "X: [0 1] y: [0] \n",
      "\tAproximacion:  [0.00034363]\n",
      "X: [0 0] y: [0] \n",
      "\tAproximacion:  [-0.00028827]\n",
      "X: [1 0] y: [0] \n",
      "\tAproximacion:  [0.00036937]\n",
      "X: [1 1] y: [1] \n",
      "\tAproximacion:  [0.98325664]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y, epochs=50001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# And\n",
    "X = np.array([[0, 1],\n",
    "              [0, 0],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    " \n",
    "y = np.array([[1],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "epochs: 10000\n",
      "X: [0 1] y: [1] \n",
      "\tAproximacion:  [0.97629469]\n",
      "X: [0 0] y: [0] \n",
      "\tAproximacion:  [0.00113128]\n",
      "X: [1 0] y: [1] \n",
      "\tAproximacion:  [0.97815186]\n",
      "X: [1 1] y: [1] \n",
      "\tAproximacion:  [0.99436356]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "X: [0 1] y: [1] \n",
      "\tAproximacion:  [0.96028761]\n",
      "X: [0 0] y: [0] \n",
      "\tAproximacion:  [0.00419791]\n",
      "X: [1 0] y: [1] \n",
      "\tAproximacion:  [0.95119924]\n",
      "X: [1 1] y: [1] \n",
      "\tAproximacion:  [0.9903503]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y, epochs=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "epochs: 10000\n",
      "epochs: 15000\n",
      "epochs: 20000\n",
      "epochs: 25000\n",
      "epochs: 30000\n",
      "epochs: 35000\n",
      "epochs: 40000\n",
      "epochs: 45000\n",
      "epochs: 50000\n",
      "X: [0 1] y: [1] \n",
      "\tAproximacion:  [0.98773139]\n",
      "X: [0 0] y: [0] \n",
      "\tAproximacion:  [0.00029107]\n",
      "X: [1 0] y: [1] \n",
      "\tAproximacion:  [0.98918482]\n",
      "X: [1 1] y: [1] \n",
      "\tAproximacion:  [0.99850818]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y, epochs=50001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# And\n",
    "X = np.array([[0, 1],\n",
    "              [0, 0],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    " \n",
    "y = np.array([[1],\n",
    "              [0],\n",
    "              [1],\n",
    "              [0]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "epochs: 10000\n",
      "X: [0 1] y: [1] \n",
      "\tAproximacion:  [0.95353668]\n",
      "X: [0 0] y: [0] \n",
      "\tAproximacion:  [0.00173207]\n",
      "X: [1 0] y: [1] \n",
      "\tAproximacion:  [0.95132908]\n",
      "X: [1 1] y: [0] \n",
      "\tAproximacion:  [0.00415304]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "X: [0 1] y: [1] \n",
      "\tAproximacion:  [0.64351828]\n",
      "X: [0 0] y: [0] \n",
      "\tAproximacion:  [0.18061695]\n",
      "X: [1 0] y: [1] \n",
      "\tAproximacion:  [0.58315306]\n",
      "X: [1 1] y: [0] \n",
      "\tAproximacion:  [0.3167121]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y, epochs=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 5000\n",
      "epochs: 10000\n",
      "epochs: 15000\n",
      "epochs: 20000\n",
      "epochs: 25000\n",
      "epochs: 30000\n",
      "epochs: 35000\n",
      "epochs: 40000\n",
      "epochs: 45000\n",
      "epochs: 50000\n",
      "X: [0 1] y: [1] \n",
      "\tAproximacion:  [0.97937955]\n",
      "X: [0 0] y: [0] \n",
      "\tAproximacion:  [0.00030344]\n",
      "X: [1 0] y: [1] \n",
      "\tAproximacion:  [0.9796585]\n",
      "X: [1 1] y: [0] \n",
      "\tAproximacion:  [0.00120609]\n"
     ]
    }
   ],
   "source": [
    "fast_training(X, y, epochs=50001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referencias \n",
    "\n",
    "[1]MIGALA D, 🔴TIPOS DE REDES NEURONALES ARTIFICIALES  (2019) | INTELIGENCIA ARTIFICIAL. 2018.\n",
    "\n",
    "[2]“Activation function”, Wikipedia. dic. 13, 2020, Consultado: dic. 16, 2020. [En línea]. Disponible en: https://en.wikipedia.org/w/index.php?title=Activation_function&oldid=993982136.\n",
    "\n",
    "[3]S. Torres y N. Nadia, “Aplicación de Redes Neuronales en controladores de baterías”, dic. 2019, Consultado: dic. 16, 2020. [En línea]. Disponible en: http://dspace.unila.edu.br:80/handle/123456789/5826.\n",
    "\n",
    "[4]P. J. Werbos, “Backpropagation through time: what it does and how to do it”, Proceedings of the IEEE, vol. 78, núm. 10, pp. 1550–1560, oct. 1990, doi: 10.1109/5.58337.\n",
    "\n",
    "[5]“Backpropagation-BP – Numerentur.org”. http://numerentur.org/backpropagation/ (consultado dic. 16, 2020).\n",
    "\n",
    "[6]“Multicapa Sobreaprendizaje Perceptron Neuronas”. https://web.archive.org/web/20140714231842/http://www.lab.inf.uc3m.es/~a0080630/redes-de-neuronas/perceptron-multicapa.html (consultado dic. 16, 2020).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
