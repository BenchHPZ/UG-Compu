{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import inf\n",
    "from collections import Counter\n",
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Codigo de norving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     16,
     20,
     24,
     28,
     32,
     42,
     48
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Spelling Corrector in Python 3; see http://norvig.com/spell-correct.html\n",
    "\n",
    "    Copyright (c) 2007-2016 Peter Norvig\n",
    "    MIT license: www.opensource.org/licenses/mit-license.php\n",
    "\"\"\"\n",
    "################ Spelling Corrector ################\n",
    "####################################################\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "################ Test Code \n",
    "\n",
    "def unit_tests():\n",
    "    assert correction('speling') == 'spelling','Err: insert'# insert\n",
    "    assert correction('korrectud') == 'corrected'           # replace 2\n",
    "    assert correction('bycycle') == 'bicycle'               # replace\n",
    "    assert correction('inconvient') == 'inconvenient'       # insert 2\n",
    "    assert correction('arrainged') == 'arranged'            # delete\n",
    "    assert correction('peotry') =='poetry'                  # transpose\n",
    "    assert correction('peotryy') =='poetry'                 # transpose + delete\n",
    "    assert correction('word') == 'word'                     # known\n",
    "    assert correction('quintessential') == 'quintessential' # unknown\n",
    "    assert words('This is a TEST.') == ['this', 'is', 'a', 'test']\n",
    "    assert Counter(words('This is a test. 123; A TEST this is.')) == (\n",
    "           Counter({'123': 1, 'a': 2, 'is': 2, 'test': 2, 'this': 2}))\n",
    "    assert len(WORDS) == 32198\n",
    "    assert sum(WORDS.values()) == 1115585\n",
    "    assert WORDS.most_common(10) == [\n",
    "        ('the', 79809),\n",
    "        ('of', 40024),\n",
    "        ('and', 38312),\n",
    "        ('to', 28765),\n",
    "        ('in', 22023),\n",
    "        ('a', 21124),\n",
    "        ('that', 12512),\n",
    "        ('he', 12401),\n",
    "        ('was', 11410),\n",
    "        ('it', 10681)]\n",
    "    assert WORDS['the'] == 79809\n",
    "    assert P('quintessential') == 0\n",
    "    assert 0.07 < P('the') < 0.08\n",
    "    return 'unit_tests pass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_tests pass\n",
      "spelling\n",
      "corrected\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "print(unit_tests())\n",
    "print(correction('speling'))\n",
    "print(correction('korrectud'))\n",
    "print(correction('thu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.La siguiente palabra m\\'as probable\n",
    "\n",
    "Usando _big.txt_ crear una funci\\'on que estime la siguiente palabra m\\'as probable dada una anterior. La funci\\'on debbe calcular \n",
    "    $$w_{i+1} = \\text{argmax}_{w_{i+1}}P(W_{i+1}|w_i)$$\n",
    "Para este trabajo\n",
    "1. Podemos asumir que ambas palabras siempre existir\\'an en la colecci\\'on\n",
    "2. Requerimos una funci\\'on similar a $P$, que calcule $P(w_1|w_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     4,
     18,
     22
    ]
   },
   "outputs": [],
   "source": [
    "################################\n",
    "### Funciones para trabajar  ###\n",
    "################################\n",
    "\n",
    "def words_from_file( fileName ):\n",
    "    \"\"\" Obtenemos las palabras de un archivo. \"\"\"\n",
    "    file = open(fileName).read()\n",
    "    return re.findall(r'\\w+', file.lower())\n",
    "\n",
    "def create_dict(texto):\n",
    "    \"\"\" Funcion para crear el diccionario auxiliar para \n",
    "    calcular las probabilidades necesarias. \n",
    "    \"\"\"\n",
    "    ret = {}\n",
    "    for i in range(1,len(texto)):\n",
    "        if texto[i] not in ret:\n",
    "            ret[texto[i]] = {}\n",
    "        if texto[i-1] not in ret[texto[i]]:\n",
    "            (ret[texto[i]])[texto[i-1]] = 0\n",
    "            \n",
    "        (ret[texto[i]])[texto[i-1]] += 1\n",
    "    \n",
    "    # Pre-ordenado\n",
    "    for word in ret:\n",
    "        ret[word] = OrderedDict(sorted(ret[word].items(), \n",
    "                                       key=lambda x: \n",
    "                                       prob_cond(x[0], word, ret),\n",
    "                                       reverse=True))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def prob_cond(a, b, dic):\n",
    "    \"\"\" Probabilidad de A dado B en funcion de dic \"\"\"\n",
    "    try:\n",
    "        return ((dic[a])[b])/sum(dic[b].values())\n",
    "    except KeyError:\n",
    "        return -1\n",
    "\n",
    "def next_word(word, dic):\n",
    "    \"\"\" Obtenemos la siguiente palabra mas probable en funcion\n",
    "    del dicionario y sus probabiliodades. \"\"\"\n",
    "    try:\n",
    "        return next(iter(dic[word]))\n",
    "    except:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new york\n",
      "0.15811258278145696\n"
     ]
    }
   ],
   "source": [
    "dic = create_dict(words_from_file('big.txt'))\n",
    "word = 'new'\n",
    "\n",
    "print( word +' '+next_word( word, dic) )\n",
    "print( prob_cond('york','new', dic) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.Aqu\\'i la maquina juega al ahorcado\n",
    "Se recomienda extender y mejorar de alg\\'un modo la funci\\'on propuesta por __Norving__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     7,
     8,
     19,
     25,
     31,
     39,
     40,
     42,
     49,
     51,
     56
    ]
   },
   "outputs": [],
   "source": [
    "def under(word):\n",
    "    word = word.split('_')\n",
    "    if len(word) > 5:\n",
    "        print('Demasiadas letras desconocidas')\n",
    "        return None\n",
    "    return word\n",
    "\n",
    "def candidatos(word):\n",
    "    '''  Recibe a word ya con el 'split' aplicado \n",
    "        y regresamos las posibles palabras \n",
    "    '''    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    n_letters = len(letters)\n",
    "    flag = word[-1] if word[-1] != '' else 'BrendA'\n",
    "    \n",
    "    # Creamos los posibles 'pedacitos' de la palabra\n",
    "    words = [ele + letter \n",
    "             for ele in word[:len(word)-1] \n",
    "             for letter in letters]\n",
    "    \n",
    "    # Variables auxiliares\n",
    "    options = words[:n_letters]\n",
    "    options_t = []\n",
    "    \n",
    "    # Concatenamos los posibles 'pedacitos'\n",
    "    for k in range( 1, len(words)//n_letters ):\n",
    "        for option in options:\n",
    "            for i in range(n_letters):\n",
    "                options_t.append(option + words[n_letters*k + i])\n",
    "        options = options_t; options_t = []\n",
    "        \n",
    "    if flag != 'BrendA': # Checamos si al final hay un '_' o una letra\n",
    "        for i in range(len(options)): \n",
    "            options[i] = options[i] + flag\n",
    "    \n",
    "    # Regresamos unicamente las palabras que esten en el diccionario\n",
    "    return set(opt for opt in options if opt in WORDS)\n",
    "\n",
    "def dist_lev(source, target):\n",
    "    if source == target: return 0\n",
    "    # Crear matriz\n",
    "    n_s, n_t = len(source), len(target)\n",
    "    dist = [[0 for i in range(n_t+1)] for x in range(n_s+1)]\n",
    "    for i in range(n_s+1): dist[i][0] = i\n",
    "    for j in range(n_t+1): dist[0][j] = j\n",
    "    # Calculando la distancia\n",
    "    for i in range(n_s):\n",
    "        for j in range(n_t):\n",
    "            cost = 0 if source[i] == target[j] else 1\n",
    "            dist[i+1][j+1] = min(\n",
    "                                    dist[i][j+1] + 1,   # deletion\n",
    "                                    dist[i+1][j] + 1,   # insertion\n",
    "                                    dist[i][j] + cost   # substitution\n",
    "                                )\n",
    "    return dist[-1][-1]\n",
    "\n",
    "def closest(word, options):\n",
    "    ret = 'BrendA', inf\n",
    "    for opt in options:\n",
    "        dist = dist_lev(word, opt)\n",
    "        ret = (opt, dist) if dist < ret[1] else ret\n",
    "    return ret\n",
    "    \n",
    "def hangman(word):\n",
    "    options = candidatos( under(word) )\n",
    "    return closest(word, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sherlock\n",
      "notebook\n",
      "hello\n",
      "people\n",
      "philosophy\n",
      "significance\n",
      "knowledge\n"
     ]
    }
   ],
   "source": [
    "print(hangman('s_e_l_c_')[0]) #sherlock\n",
    "print(hangman('no_eb_o_')[0]) #notebook\n",
    "print(hangman('he__o')[0])    #hello\n",
    "\n",
    "print(hangman('pe_p_e')[0]) #people\n",
    "print(hangman('phi__sop_y')[0]) #philospphy\n",
    "print(hangman('si_nif_c_nc_')[0]) #significance\n",
    "print(hangman('kn__l_d_e')[0])      #sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.Ahorcado al extremo\n",
    "Unir la funci\\'on de _2_ y _2.1_ para, utilizando una palabra de contexto, completar palabras con mayor precisi\\'on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     2,
     4,
     10,
     12,
     22
    ]
   },
   "outputs": [],
   "source": [
    "def super_under(word):\n",
    "    ct = Counter(word)\n",
    "    if len(word) - ct['_'] < 1:\n",
    "        print('Demasiadas letras desconocidas')\n",
    "        return None\n",
    "    word = word.split('_')\n",
    "    return word\n",
    "\n",
    "def super_closest( context, options):\n",
    "    ret = 'BrendA', -inf\n",
    "    for opt in options:  # Buscando el ret adecuado\n",
    "        # Esta es la misma funcion de probabilidad del ejercicio anterior\n",
    "        prob = prob_cond(opt, context, dic)\n",
    "        #  En caso de que las proabilidades empaten\n",
    "        # utilizamos las distancia entre las palabras\n",
    "        # para responder.\n",
    "        ret = ((opt, prob) if dist_lev(context, opt) < dist_lev(context, ret[0]) else ret) if prob == ret[1] else ret\n",
    "        ret = (opt, prob) if prob > ret[1] else ret               \n",
    "    return ret\n",
    "\n",
    "def super_hangman(context, word):\n",
    "    options = candidatos( super_under(word) )\n",
    "    return super_closest(context, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('holmes', 1.0)\n",
      "('states', 0.7620751341681574)\n",
      "('house', 0.037142857142857144)\n",
      "('york', 0.15811258278145696)\n",
      "('lincoln', 0.6666666666666666)\n"
     ]
    }
   ],
   "source": [
    "print(super_hangman('sherlock', '_____s'))  #holmes\n",
    "print(super_hangman('united', '_t_t__'))    #states\n",
    "print(super_hangman('white', '___s_'))      #house\n",
    "print(super_hangman('new', 'y___'))         #york\n",
    "print(super_hangman('abraham', 'l_____n'))  #lincoln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Correci\\'on ortografica simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     8
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 files loaded . \n",
      "['scientists', 'witness', 'huge', 'cosmic', 'crash', 'find', 'origins', 'of', 'gold', 'even']\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "\n",
    "# simple extraction of words\n",
    "def words (text) : \n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "# siple loading of the documents\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "def get_texts_from_catdir( catdir ):\n",
    "    texts = [ ]\n",
    "    TARGET_DIR = catdir # \"./target\"\n",
    "    for f_name in sorted( os.listdir( TARGET_DIR )) :\n",
    "        if f_name.endswith('.txt'):\n",
    "            f_path = os.path.join( TARGET_DIR, f_name )\n",
    "            #print(f_name)\n",
    "            #print(f_path)\n",
    "            f = open( f_path , 'r', encoding='utf8' )\n",
    "            #print( f_name )\n",
    "            texts += [ f.read( ) ]\n",
    "            f.close( )\n",
    "    print( '%d files loaded . ' %len(texts) )\n",
    "    return texts\n",
    "\n",
    "# Load the RAW text\n",
    "target_txt = get_texts_from_catdir( './target' )\n",
    "\n",
    "# Print first 10 words in document0\n",
    "print( words(target_txt[0])[:10] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mezclar diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     3,
     6,
     12,
     14
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80337\n",
      "[('the', 80337), ('of', 40265), ('and', 38564), ('to', 29063), ('in', 22262)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "with open('WORDS_IN_NEWS.txt', 'r') as infile: # Exportando WORDS_IN_NEWS\n",
    "    WORDS_IN_NEWS = json.load( infile )\n",
    "WORDS_IN_NEWS = Counter(WORDS_IN_NEWS)\n",
    "\n",
    "WORDS = WORDS + WORDS_IN_NEWS\n",
    "print(WORDS['the'])\n",
    "print(WORDS.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detectar las plabras mal escritas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('detcted', ['detected']), ('intoo', ['into'])]\n",
      "[('conttinue', ['continue'])]\n",
      "[('thhe', ['thee', 'the'])]\n",
      "[('statment', ['statement'])]\n",
      "[('watchng', ['watching'])]\n",
      "[('possiblle', ['possible'])]\n",
      "[('saiid', ['said'])]\n",
      "[('addresss', ['address', 'addresses'])]\n",
      "[('essetially', ['essentially'])]\n",
      "[('gennerral', ['general'])]\n"
     ]
    }
   ],
   "source": [
    "def mispelled_and_candidates( target_words ):\n",
    "    mispelled_candidates = []\n",
    "    for word in target_words:\n",
    "        temp = list(candidates(word))  # candidates de Norving\n",
    "        if len(temp) > 1:\n",
    "            temp.sort(key=lambda x: dist_lev(word, x))\n",
    "            mispelled_candidates.append((word, temp[:10])) #Tomamos las primeras 10\n",
    "    return mispelled_candidates\n",
    "\n",
    "def mispelled_and_candidates( target_words ):\n",
    "    mispelled_candidates = []\n",
    "    \n",
    "    for word in target_words:\n",
    "        candidatos = list(candidates(word))\n",
    "        candidatos.sort(key=lambda x: dist_lev(word, x))\n",
    "        if len(candidatos) > 1:\n",
    "            # En caso de que haya una opcion\n",
    "            mispelled_candidates.append((word, candidatos[:10]))\n",
    "        elif len(candidatos) == 1 and word not in candidatos:\n",
    "            # En caso de que la unica opcion sea distinta\n",
    "            mispelled_candidates.append((word, candidatos))\n",
    "\n",
    "    return mispelled_candidates\n",
    "\n",
    "#print ( mispelled_and_candidates( words( target_txt[0] )))\n",
    "\n",
    "# Print misspelled words and candidates for each document in\n",
    "# target_txt  list\n",
    "for text in target_txt:\n",
    "    print ( mispelled_and_candidates ( words ( text ) ) )\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion completa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio supondremos que la primera palabra esta bien escrita y tiene sentido. \n",
    "\n",
    "La funcion `spell_correction` tiene una caracteristica que puede o no mejorar dependiendo de ciertos casos. De manera general, primero pasamos por la funcion del iniciso anterior al texto e identificamos todas las palabras mal escritas, luego, priorizando la probabilidad que ofrece la palabra anterior, escogemos la mejor opcione de entre aquellas que se generen por `candidates` _de Norvng_.\n",
    "\n",
    "Esta forma de actuar tiene la principal desventaja de que no detectara problemas como las ultimas dos pruebas (ejemplos) que se proponen. Donde son palabras bien escritas pero que no necesariamente son las correctas, para solucionar esto podemos dar una propuesta mas agresva donde, en caso de que la palabra que probabilisticamente halbando (y en funcion con el corpus) deberia de seguir, la ponemos sin preguntar. Esto permite solucionar mas incisos del ejemplo, pero tambien descompone otras partes (como se puede ver en las pruebas de las noticias)\n",
    "\n",
    "En general creo que aqui es donde podemos darle la opcion al humano para que escoja la palabra que mejor se acomode. Para superar esto podriamos ampliar el corpus o considerar la palabra que mejor se complemente con la que sigue. En caso de empezar con estasconsideraciones me parece que seria mejor primero arreglar todos las palabras que estan claramente mal escritas y luego hacer otra pasada con probabilidades.\n",
    "\n",
    "\n",
    "#### Nota\n",
    "\n",
    "Dado que _ham_ no parece estar en el corpus, causa problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de diccionario ampliado\n",
    "# Aunque no sirve de mucho\n",
    "nbig = open('big.txt').read()\n",
    "for text in target_txt:\n",
    "    nbig += text\n",
    "    \n",
    "dic = create_dict(words(nbig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'hav', 'a', 'ham']\n",
      "['i', 'have', 'a', 'man']\n",
      "\n",
      "['my', 'countr', 'is', 'biig']\n",
      "['my', 'country', 'is', 'big']\n",
      "\n",
      "['i', 'want', 't00', 'eat']\n",
      "['i', 'want', 'to', 'eat']\n",
      "\n",
      "['the', 'science', '0ff', 'computer']\n",
      "['the', 'science', 'of', 'computer']\n",
      "\n",
      "['the', 'science', 'off', 'computer']\n",
      "['the', 'science', 'of', 'computer']\n",
      "\n",
      "['i', 'want', 'too', 'eat']\n",
      "['i', 'want', 'to', 'eat']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def spell_correction( input_text, max_dist=2, profundo=False):\n",
    "    \"\"\" Profundo le da mas libertad a la maquia para mejorar el texto. \"\"\"\n",
    "    corrected_text = input_text\n",
    "    mispeled = dict(mispelled_and_candidates(input_text))\n",
    "    \n",
    "    for iw in range(1, len(input_text)):\n",
    "        pword = corrected_text[iw-1]\n",
    "        \n",
    "        word = input_text[iw]\n",
    "        nword = next_word(pword, dic)\n",
    "        \n",
    "        # En otro caso consideramos las probabilidades\n",
    "        if word in mispeled:\n",
    "            corrected_text[iw] = max(mispeled[word], \n",
    "                              key=lambda x: prob_cond(x, pword, dic))\n",
    "        # Si se parecem cambiamos sin preguntar\n",
    "        if profundo and dist_lev(nword, word) <= max_dist:\n",
    "            corrected_text[iw] = nword\n",
    "\n",
    "    return corrected_text\n",
    "\n",
    "tests = [['i', 'hav', 'a', 'ham'],\n",
    "     ['my', 'countr', 'is', 'biig'],\n",
    "     ['i', 'want', 't00', 'eat'],\n",
    "     ['the', 'science', '0ff', 'computer'],\n",
    "     ['the', 'science', 'off', 'computer'],\n",
    "     [ 'i', 'want' , 'too' , 'eat']\n",
    "    ]\n",
    "for s in tests:\n",
    "    #print(mispelled_and_candidates(s))\n",
    "    print(s)\n",
    "    print( spell_correction( s, profundo=True ))\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chequeo con Golden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 files loaded . \n",
      "0 => detected != detcted\n",
      "1 => into != intoo\n",
      "2 => continue != conttinue\n",
      "3 => the != thhe\n",
      "4 => statement != statment\n",
      "5 => watching != watchng\n",
      "6 => possible != possiblle\n",
      "7 => said != saiid\n",
      "8 => address != addresss\n",
      "9 => essentially != essetially\n",
      "10 => general != gennerral\n"
     ]
    }
   ],
   "source": [
    "golden_txt = get_texts_from_catdir( './golden' )\n",
    "golden_words = words(\" \".join(golden_txt))\n",
    "target_words = words(\" \".join(target_txt))\n",
    "\n",
    "i = 0\n",
    "for gword, tword in zip(golden_words, target_words):\n",
    "    if gword != tword:\n",
    "        print(f\"{i} => {gword} != {tword}\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-----|!!! No hay errores =D !!!|----->\n"
     ]
    }
   ],
   "source": [
    "new_text = spell_correction(target_words)\n",
    "new_words = words(\" \".join(new_text))\n",
    "\n",
    "i = 0\n",
    "for gword, nword in zip(golden_words, new_words):\n",
    "    if gword != nword:\n",
    "        print(f\"{i} => {gword} != {nword}\")\n",
    "        i+=1\n",
    "else:\n",
    "    if i==0:\n",
    "        print(\"<-----|!!! No hay errores =D !!!|----->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => in != if\n",
      "1 => ago != and\n",
      "2 => the != that\n",
      "3 => two != the\n",
      "4 => to != as\n",
      "5 => of != a\n",
      "6 => a != man\n",
      "7 => star != stars\n",
      "8 => a != to\n",
      "9 => a != it\n",
      "10 => an != a\n",
      "11 => to != in\n",
      "12 => on != i\n",
      "13 => the != to\n",
      "14 => one != be\n",
      "15 => we != the\n",
      "16 => in != of\n",
      "17 => would != gold\n",
      "18 => s != of\n",
      "19 => at != of\n",
      "20 => we != to\n",
      "21 => ve != be\n",
      "22 => this != the\n",
      "23 => the != to\n",
      "24 => on != and\n",
      "25 => 5 != to\n",
      "26 => 88 != be\n",
      "27 => the != to\n",
      "28 => in != and\n",
      "29 => how != to\n",
      "30 => are != and\n",
      "31 => for != to\n",
      "32 => 4 != in\n",
      "33 => the != he\n",
      "34 => this != the\n",
      "35 => s != of\n",
      "36 => out != you\n",
      "37 => the != are\n",
      "38 => 1 != he\n",
      "39 => are != he\n",
      "40 => a != had\n",
      "41 => was != is\n",
      "42 => to != s\n",
      "43 => of != a\n",
      "44 => this != the\n",
      "45 => to != of\n",
      "46 => the != her\n",
      "47 => that != the\n",
      "48 => into != it\n",
      "49 => said != and\n",
      "50 => has != he\n",
      "51 => 60 != in\n",
      "52 => do != he\n",
      "53 => that != the\n",
      "54 => have != he\n",
      "55 => was != is\n",
      "56 => said != david\n",
      "57 => in != and\n",
      "58 => we != he\n",
      "59 => in != and\n",
      "60 => said != and\n",
      "61 => the != to\n",
      "62 => one != the\n",
      "63 => on != and\n",
      "64 => any != a\n",
      "65 => that != this\n",
      "66 => get != be\n",
      "67 => in != and\n",
      "68 => the != he\n",
      "69 => said != david\n",
      "70 => the != her\n",
      "71 => this != the\n",
      "72 => they != the\n",
      "73 => 20 != in\n",
      "74 => a != and\n",
      "75 => to != the\n",
      "76 => we != he\n",
      "77 => at != a\n",
      "78 => we != of\n",
      "79 => this != him\n",
      "80 => it != he\n",
      "81 => has != had\n",
      "82 => been != then\n",
      "83 => a != he\n",
      "84 => as != to\n",
      "85 => to != it\n",
      "86 => in != twin\n",
      "87 => the != those\n",
      "88 => on != of\n",
      "89 => as != last\n",
      "90 => the != to\n",
      "91 => in != and\n",
      "92 => other != over\n",
      "93 => in != and\n",
      "94 => at != of\n",
      "95 => up != in\n",
      "96 => and != a\n",
      "97 => it != him\n",
      "98 => this != the\n",
      "99 => has != al\n",
      "100 => to != of\n",
      "101 => their != the\n",
      "102 => as != last\n",
      "103 => as != of\n",
      "104 => man != and\n",
      "105 => in != and\n",
      "106 => the != them\n",
      "107 => 70 != in\n",
      "108 => to != as\n",
      "109 => had != and\n",
      "110 => he != a\n",
      "111 => to != of\n",
      "112 => the != to\n",
      "113 => s != us\n",
      "114 => a != and\n",
      "115 => is != he\n",
      "116 => two != the\n",
      "117 => has != al\n",
      "118 => a != and\n",
      "119 => of != _\n",
      "120 => in != of\n",
      "121 => at != and\n",
      "122 => a != in\n",
      "123 => said != and\n",
      "124 => the != them\n",
      "125 => to != the\n",
      "126 => we != the\n",
      "127 => in != and\n",
      "128 => we != of\n",
      "129 => for != to\n",
      "130 => a != be\n",
      "131 => for != of\n",
      "132 => those != the\n",
      "133 => said != and\n",
      "134 => face != same\n",
      "135 => this != the\n",
      "136 => the != her\n",
      "137 => to != the\n",
      "138 => at != and\n",
      "139 => for != to\n",
      "140 => in != and\n",
      "141 => the != he\n",
      "142 => the != that\n",
      "143 => to != of\n",
      "144 => the != there\n",
      "145 => an != a\n",
      "146 => to != a\n",
      "147 => after != later\n",
      "148 => in != and\n",
      "149 => to != a\n",
      "150 => for != of\n",
      "151 => a != of\n",
      "152 => he != a\n",
      "153 => was != man\n",
      "154 => a != and\n",
      "155 => this != the\n",
      "156 => he != a\n",
      "157 => was != man\n",
      "158 => by != s\n",
      "159 => in != to\n",
      "160 => to != in\n",
      "161 => at != by\n",
      "162 => bay != at\n",
      "163 => a != by\n",
      "164 => a != of\n",
      "165 => the != he\n",
      "166 => be != of\n",
      "167 => to != not\n",
      "168 => a != to\n",
      "169 => is != he\n",
      "170 => to != the\n",
      "171 => a != and\n",
      "172 => for != of\n",
      "173 => his != him\n",
      "174 => who != two\n",
      "175 => in != and\n",
      "176 => he != the\n",
      "177 => case != same\n",
      "178 => t != i\n",
      "179 => as != of\n",
      "180 => is != he\n",
      "181 => out != not\n",
      "182 => in != and\n",
      "183 => to != of\n",
      "184 => he != the\n",
      "185 => he != it\n",
      "186 => his != it\n",
      "187 => s != of\n",
      "188 => to != he\n",
      "189 => the != be\n",
      "190 => of != to\n",
      "191 => he != of\n",
      "192 => he != the\n",
      "193 => he != him\n",
      "194 => he != the\n",
      "195 => said != same\n",
      "196 => that != they\n",
      "197 => then != this\n",
      "198 => plan != man\n",
      "199 => to != s\n",
      "200 => to != the\n",
      "201 => had != have\n",
      "202 => i != he\n",
      "203 => was != had\n",
      "204 => to != on\n",
      "205 => the != be\n",
      "206 => i != he\n",
      "207 => was != had\n",
      "208 => i != he\n",
      "209 => be != he\n",
      "210 => what != had\n",
      "211 => those != the\n",
      "212 => go != he\n",
      "213 => the != be\n",
      "214 => those != the\n",
      "215 => they != the\n",
      "216 => that != the\n",
      "217 => to != he\n",
      "218 => i != to\n",
      "219 => i != is\n",
      "220 => me != to\n",
      "221 => i != he\n",
      "222 => am != had\n",
      "223 => i != a\n",
      "224 => don != man\n",
      "225 => t != s\n",
      "226 => said != had\n",
      "227 => 20 != in\n",
      "228 => they != the\n",
      "229 => for != of\n",
      "230 => an != it\n",
      "231 => the != her\n",
      "232 => of != it\n",
      "233 => for != to\n",
      "234 => we != a\n",
      "235 => t != i\n",
      "236 => any != away\n",
      "237 => to != a\n",
      "238 => he != the\n",
      "239 => t != i\n",
      "240 => he != it\n",
      "241 => the != when\n",
      "242 => s != in\n",
      "243 => 7 != a\n",
      "244 => was != is\n",
      "245 => no != to\n",
      "246 => that != the\n",
      "247 => in != its\n",
      "248 => that != the\n",
      "249 => as != do\n",
      "250 => woman != man\n",
      "251 => her != be\n",
      "252 => i != a\n",
      "253 => i != it\n",
      "254 => ve != is\n",
      "255 => not != to\n",
      "256 => ago != as\n",
      "257 => then != the\n",
      "258 => it != a\n",
      "259 => me != the\n",
      "260 => 34 != it\n",
      "261 => an != and\n",
      "262 => to != the\n",
      "263 => was != is\n",
      "264 => did != i\n",
      "265 => the != her\n",
      "266 => an != a\n",
      "267 => and != a\n",
      "268 => one != and\n",
      "269 => in != do\n",
      "270 => an != in\n",
      "271 => the != her\n",
      "272 => off != of\n",
      "273 => on != of\n",
      "274 => to != of\n",
      "275 => a != be\n",
      "276 => the != be\n",
      "277 => to != of\n",
      "278 => it != or\n",
      "279 => the != one\n",
      "280 => see != are\n",
      "281 => a != be\n",
      "282 => on != to\n",
      "283 => t != be\n",
      "284 => on != and\n",
      "285 => it != a\n",
      "286 => if != i\n",
      "287 => have != are\n",
      "288 => it != i\n",
      "289 => they != he\n",
      "290 => to != tv\n",
      "291 => to != the\n",
      "292 => of != not\n",
      "293 => a != to\n",
      "294 => set != be\n",
      "295 => top != the\n",
      "296 => now != for\n",
      "297 => the != he\n",
      "298 => at != to\n",
      "299 => t != be\n",
      "300 => to != the\n",
      "301 => has != he\n",
      "302 => a != had\n",
      "303 => s != an\n",
      "304 => use != the\n",
      "305 => if != of\n",
      "306 => re != are\n",
      "307 => tie != be\n",
      "308 => a != and\n",
      "309 => as != and\n",
      "310 => at != a\n",
      "311 => in != and\n",
      "312 => for != of\n",
      "313 => to != you\n",
      "314 => up != to\n",
      "315 => tv != an\n",
      "316 => in != and\n",
      "317 => that != the\n",
      "318 => the != then\n",
      "319 => a != to\n",
      "320 => lg != a\n",
      "321 => by != to\n",
      "322 => the != be\n",
      "323 => the != he\n",
      "324 => ends != and\n",
      "325 => 50 != to\n",
      "326 => per != be\n",
      "327 => it != i\n",
      "328 => time != the\n",
      "329 => in != and\n",
      "330 => at != not\n",
      "331 => use != be\n",
      "332 => this != the\n",
      "333 => s != a\n",
      "334 => use != be\n",
      "335 => that != the\n",
      "336 => the != to\n",
      "337 => 7 != a\n",
      "338 => a != man\n",
      "339 => on != and\n",
      "340 => at != to\n",
      "341 => at != a\n",
      "342 => tv != the\n",
      "343 => to != the\n",
      "344 => tv != so\n",
      "345 => use != be\n",
      "346 => that != the\n",
      "347 => tv != the\n",
      "348 => on != a\n",
      "349 => a != man\n",
      "350 => tv != of\n",
      "351 => the != he\n",
      "352 => or != your\n",
      "353 => its != to\n",
      "354 => app != and\n",
      "355 => for != to\n",
      "356 => a != in\n",
      "357 => s != tv\n",
      "358 => you != to\n",
      "359 => to != be\n",
      "360 => tv != or\n",
      "361 => 50 != to\n",
      "362 => a != be\n",
      "363 => has != he\n",
      "364 => an != to\n",
      "365 => to != the\n",
      "366 => and != in\n",
      "367 => it != a\n",
      "368 => a != to\n",
      "369 => rob != for\n",
      "370 => a != to\n",
      "371 => d != and\n",
      "372 => c != a\n",
      "373 => a != to\n",
      "374 => e != of\n",
      "375 => at != and\n",
      "376 => him != it\n",
      "377 => on != is\n",
      "378 => s != is\n",
      "379 => got != to\n",
      "380 => or != for\n",
      "381 => now != not\n",
      "382 => be != to\n",
      "383 => able != be\n",
      "384 => to != the\n",
      "385 => and != a\n",
      "386 => these != the\n",
      "387 => to != now\n",
      "388 => be != he\n",
      "389 => as != had\n",
      "390 => as != and\n",
      "391 => so != to\n",
      "392 => and != a\n",
      "393 => it != to\n",
      "394 => in != and\n",
      "395 => in != of\n",
      "396 => if != to\n",
      "397 => the != be\n",
      "398 => or != for\n",
      "399 => one != he\n",
      "400 => to != a\n",
      "401 => you != of\n",
      "402 => to != you\n",
      "403 => a != it\n",
      "404 => s != is\n",
      "405 => ios != his\n",
      "406 => a != so\n",
      "407 => an != so\n",
      "408 => said != and\n",
      "409 => in != of\n",
      "410 => at != and\n",
      "411 => said != and\n",
      "412 => in != a\n",
      "413 => an != man\n",
      "414 => to != the\n",
      "415 => not != you\n",
      "416 => a != to\n",
      "417 => on != to\n",
      "418 => the != be\n",
      "419 => one != the\n",
      "420 => are != have\n",
      "421 => than != the\n",
      "422 => is != of\n",
      "423 => in != and\n",
      "424 => a != be\n",
      "425 => in != of\n",
      "426 => air != and\n",
      "427 => in != and\n",
      "428 => 3 != in\n",
      "429 => in != and\n",
      "430 => for != of\n",
      "431 => ag != and\n",
      "432 => in != of\n",
      "433 => not != it\n",
      "434 => as != and\n",
      "435 => the != to\n",
      "436 => a != way\n",
      "437 => on != and\n",
      "438 => due != the\n",
      "439 => the != be\n",
      "440 => on != to\n",
      "441 => the != be\n",
      "442 => no != a\n",
      "443 => than != the\n",
      "444 => the != than\n",
      "445 => said != and\n",
      "446 => its != it\n",
      "447 => is != as\n",
      "448 => to != the\n",
      "449 => at != and\n",
      "450 => 3 != to\n",
      "451 => in != to\n",
      "452 => the != be\n",
      "453 => to != the\n",
      "454 => its != is\n",
      "455 => on != of\n",
      "456 => this != his\n",
      "457 => in != s\n",
      "458 => can != and\n",
      "459 => so != tv\n",
      "460 => one != and\n",
      "461 => of != k5\n",
      "462 => u != he\n",
      "463 => a != be\n",
      "464 => the != other\n",
      "465 => u != he\n",
      "466 => law != a\n",
      "467 => t != he\n",
      "468 => in != by\n",
      "469 => if != he\n",
      "470 => was != is\n",
      "471 => do != be\n",
      "472 => u != of\n",
      "473 => u != he\n",
      "474 => had != and\n",
      "475 => to != a\n",
      "476 => hand != man\n",
      "477 => the != to\n",
      "478 => for != to\n",
      "479 => the != be\n",
      "480 => by != of\n",
      "481 => to != in\n",
      "482 => case != same\n",
      "483 => are != the\n",
      "484 => they != the\n",
      "485 => have != he\n",
      "486 => no != to\n",
      "487 => s != he\n",
      "488 => as != of\n",
      "489 => in != as\n",
      "490 => is != in\n",
      "491 => in != to\n",
      "492 => to != in\n",
      "493 => act != a\n",
      "494 => the != to\n",
      "495 => said != had\n",
      "496 => an != to\n",
      "497 => in != of\n",
      "498 => it != of\n",
      "499 => for != to\n",
      "500 => to != in\n",
      "501 => act != a\n",
      "502 => to != of\n",
      "503 => take != the\n",
      "504 => case != same\n",
      "505 => for != not\n",
      "506 => s != of\n",
      "507 => is != he\n",
      "508 => in != is\n",
      "509 => on != to\n",
      "510 => the != be\n",
      "511 => the != he\n",
      "512 => the != her\n",
      "513 => to != of\n",
      "514 => in != and\n",
      "515 => are != at\n",
      "516 => to != not\n",
      "517 => is != in\n",
      "518 => to != the\n",
      "519 => the != to\n",
      "520 => the != he\n",
      "521 => the != be\n",
      "522 => a != of\n",
      "523 => to != the\n",
      "524 => for != of\n",
      "525 => a != to\n",
      "526 => the != he\n",
      "527 => u != he\n",
      "528 => law != a\n",
      "529 => no != to\n",
      "530 => in != he\n",
      "531 => their != the\n",
      "532 => its != in\n",
      "533 => or != of\n",
      "534 => a != it\n",
      "535 => more != for\n",
      "536 => to != of\n",
      "537 => what != that\n",
      "538 => is != to\n",
      "539 => it != to\n",
      "540 => it != is\n",
      "541 => is != it\n",
      "542 => that != the\n",
      "543 => buy != be\n",
      "544 => as != of\n",
      "545 => are != and\n",
      "546 => buy != be\n",
      "547 => an != a\n",
      "548 => a != and\n",
      "549 => t != be\n",
      "550 => be != the\n",
      "551 => of != it\n",
      "552 => in != of\n",
      "553 => end != and\n",
      "554 => up != a\n",
      "555 => buy != be\n",
      "556 => it != i\n",
      "557 => win != man\n",
      "558 => in != and\n",
      "559 => the != he\n",
      "560 => if != i\n",
      "561 => stop != ship\n",
      "562 => it != of\n",
      "563 => to != in\n",
      "564 => in != a\n",
      "565 => an != or\n",
      "566 => this != the\n",
      "567 => time != same\n",
      "568 => s != of\n",
      "569 => more != for\n",
      "570 => t != be\n",
      "571 => his != him\n",
      "572 => this != the\n",
      "573 => a != to\n",
      "574 => to != a\n",
      "575 => is != of\n",
      "576 => as != if\n",
      "577 => his != he\n",
      "578 => in != and\n",
      "579 => t != i\n",
      "580 => rape != have\n",
      "581 => has != had\n",
      "582 => in != and\n",
      "583 => way != man\n",
      "584 => not != you\n",
      "585 => more != are\n",
      "586 => are != and\n",
      "587 => as != and\n",
      "588 => and != as\n",
      "589 => is != he\n",
      "590 => i != is\n",
      "591 => it != i\n",
      "592 => t != i\n",
      "593 => as != and\n",
      "594 => us != a\n",
      "595 => it != i\n",
      "596 => the != he\n",
      "597 => the != he\n",
      "598 => can != and\n",
      "599 => t != a\n",
      "600 => i != so\n",
      "601 => it != i\n",
      "602 => if != he\n",
      "603 => re != were\n",
      "604 => go != not\n",
      "605 => was != had\n",
      "606 => of != an\n",
      "607 => as != of\n",
      "608 => a != to\n",
      "609 => he != is\n",
      "610 => re != were\n",
      "611 => he != is\n",
      "612 => and != a\n",
      "613 => re != were\n",
      "614 => the != to\n",
      "615 => i != a\n",
      "616 => don != man\n",
      "617 => t != s\n",
      "618 => it != i\n",
      "619 => a != to\n",
      "620 => man != and\n",
      "621 => he != i\n",
      "622 => not != to\n",
      "623 => all != and\n",
      "624 => of != a\n",
      "625 => as != and\n",
      "626 => is != of\n",
      "627 => there != the\n",
      "628 => in != of\n",
      "629 => s != is\n",
      "630 => a != to\n",
      "631 => there != the\n",
      "632 => no != a\n",
      "633 => do != of\n",
      "634 => in != a\n",
      "635 => in != of\n",
      "636 => the != her\n",
      "637 => she != he\n",
      "638 => get != be\n",
      "639 => the != to\n",
      "640 => it != of\n",
      "641 => a != of\n",
      "642 => in != as\n",
      "643 => or != of\n",
      "644 => want != was\n",
      "645 => to != a\n",
      "646 => do != be\n",
      "647 => a != to\n",
      "648 => or != of\n",
      "649 => a != if\n",
      "650 => a != way\n",
      "651 => them != the\n",
      "652 => it != to\n",
      "653 => man != and\n",
      "654 => to != so\n",
      "655 => in != and\n",
      "656 => his != if\n",
      "657 => don != in\n",
      "658 => by != be\n",
      "659 => and != a\n",
      "660 => t != i\n",
      " ='( Ahora si )'=\n"
     ]
    }
   ],
   "source": [
    "new_text = spell_correction(target_words, profundo=True)\n",
    "new_words = words(\" \".join(new_text))\n",
    "\n",
    "i = 0\n",
    "for gword, nword in zip(golden_words, new_words):\n",
    "    if gword != nword:\n",
    "        print(f\"{i} => {gword} != {nword}\")\n",
    "        i+=1\n",
    "else:\n",
    "    if i==0:\n",
    "        print(\"<-----|!!! No hay errores =D !!!|----->\")\n",
    "    else:\n",
    "        print(\" ='( Ahora si )'=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
