{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea Final de Inteligencia Artificial\n",
    "\n",
    "Benjamin Rivera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal\n",
    "\n",
    "Objetivo:  entrenar  una  red  neuronal  tipo  perceptrón  multicapas  que  aprenda  a  clasificar correctamente un conjunto de datos.  Luego de entrenar hasta conseguir un  error  de  entrenamiento    cercano  a  cero,  vamos  a  comprobar  qué  tan  bien funciona la red midiendo el error de validación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacion de Red Neuronal (Previo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de Activacion \n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def identity_derivada(x):\n",
    "    return 1\n",
    "\n",
    "def relu(x):\n",
    "    return 0 if np.all(x <= 0) else x\n",
    "\n",
    "def relu_derivada(x):\n",
    "    # Simplificacion para evitar errores.\n",
    "    return 0 if np.all(x <= 0) else 1\n",
    "\n",
    "def step(x):\n",
    "    return 0 if x < 0 else 1\n",
    "\n",
    "def step_derivada(x):\n",
    "    # Simplificacion para evitar errores.\n",
    "    return 0\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivada(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivada(x):\n",
    "    return 1.0 - x**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\" Clase para generalizar redes neuronales feedforward.\n",
    "    \n",
    "    Esta clase tiene como objetivo la generalizacion de las redes neurona_\n",
    "    les feedforward. Esta generalizacion no permite hacer modificaciones \n",
    "    a la estructura estandar donde todos los nodos (a exepcion de los de \n",
    "    salida) se comportan como perceptrones conectados a las siguientes \n",
    "    capas.\n",
    "    \n",
    "    Se tiene un unico constructor que inicializa todo como se pide\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, activation='tanh', w_range = (-1,1)):\n",
    "        # Verificacion de datos de entrada\n",
    "        if activation not in ['sigmoid', 'tanh', 'relu', 'step', 'identity']:\n",
    "            raise Exception(\"Funcion de activacion no reconocida. \")\n",
    "        if w_range[0] >= w_range[1]:\n",
    "            raise Exception(\"Error en el rango de los pesos. \")\n",
    "        \n",
    "        # Seleccion de funcion de activacion\n",
    "        if activation == 'relu':\n",
    "            self.activation = relu\n",
    "            self.activation_prime = relu_derivada\n",
    "        elif activation == 'step':\n",
    "            self.activaition = step\n",
    "            self.activation_prime = step_derivada\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = sigmoid\n",
    "            self.activation_prime = sigmoid_derivada\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_prime = tanh_derivada\n",
    "        elif activation == 'identity':\n",
    "            self.activation = identity\n",
    "            self.activation_prime = identity_derivada\n",
    "\n",
    "        # Inicializacion de pesos\n",
    "        self.weights = []\n",
    "        self.deltas = []\n",
    "        # valores aleatorios a pesos de entrada y capa oculta\n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = np.random.uniform(w_range[0], w_range[1], (layers[i-1] + 1, layers[i] + 1))\n",
    "            self.weights.append(r)\n",
    "        # valores aleatorios a capa de salida\n",
    "        r = np.random.uniform(w_range[0], w_range[1], (layers[i] + 1, layers[i+1]))\n",
    "        self.weights.append(r)\n",
    "\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.1, epochs=100000, with_bias=False):\n",
    "        \"\"\" Funcion para realizar la aproximacion del modelo a los datos dados.\n",
    "        \n",
    "        Esta funcion trata de ajustar los pesos de la red (backpropagation) para\n",
    "        que se ajuste a los datos dados. Permite que se ajuste el \"ratio de \n",
    "        aprendizaje\" y la cantidad de iteraciones para el entrenamiento.\n",
    "        \n",
    "        Input:\n",
    "            X := Datos de la capa de entrada\n",
    "            y := Datos esperados en la capa de salida\n",
    "            learning_rate := Ratio de aprendizaje del modelo\n",
    "            epochs := Cantidad de iteraciones para el modelo\n",
    "        \"\"\"\n",
    "\n",
    "        # Agregamos bias si no lo tiene ya\n",
    "        if not with_bias:\n",
    "            ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "            X = np.concatenate((ones.T, X), axis=1)\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "\n",
    "            # Calculo del error en el modelo\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "            \n",
    "            # Calculamos los deltas\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "            self.deltas.append(deltas)\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 10000 == 0: print('epochs:', k)\n",
    "\n",
    "    def evaluate(self, x):\n",
    "        \"\"\" Funcion para evaluar una entrada en la red. \"\"\"\n",
    "        \n",
    "        ones = np.atleast_2d(np.ones(x.shape[0]))\n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)), axis=0)\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "            \n",
    "        return a\n",
    "            \n",
    "    def set_weights(self, w):\n",
    "        \"\"\" Funcion establecer ciertos pesos. \"\"\"\n",
    "        try:\n",
    "            if w.shape == self.weights.shape:\n",
    "                self.weights = w\n",
    "        except AttributeError as e:\n",
    "            print(\"Los pesos se mantienen. \")\n",
    "            print(e)\n",
    "    \n",
    "    # Getters\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def get_deltas(self):\n",
    "        return self.deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_training(X, y, hiden_layers=[3], epochs=15000, learning_rate=0.02, activation='identity', with_bias=False):\n",
    "    \"\"\" Implementacion simplificada. Regresa la red para hacer mas pruebas. \"\"\"\n",
    "    if with_bias:\n",
    "        layers = [len(X[0])-1, len(y[0])]\n",
    "    else:\n",
    "        layers = [len(X[0]), len(y[0])]\n",
    "        \n",
    "    for lay in hiden_layers:\n",
    "        layers.insert(-1, lay)\n",
    "\n",
    "    nn = NeuralNetwork(layers, activation=activation)\n",
    "    nn.fit(X, y, learning_rate=learning_rate, epochs=epochs, with_bias=with_bias)\n",
    "\n",
    "    for i in range(0, len(X), 9):\n",
    "        print(\"X:\", X[i], \"y:\", y[i], \"\\n\\tAproximacion: \", nn.evaluate(X[i]))\n",
    "        \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1. \n",
    "Generar aleatoriamiente 100 muestras, 50 de la clase positiva y 50 de la clase negativa.  Cada muestra vive en dos dimensiones $(X1, X2)$ y tiene su etiqueta $Y$ que vale $1$ si la muestra es positiva, $0$ si es negativa. Entonces el conjunto de muestras son ternas $(X1,X2,Y)$.\n",
    "\n",
    "(Esto se debe trabajar junto co el paso 5)\n",
    "\n",
    "#### Paso 5\n",
    "\n",
    "La muestras positivas están delimitadas por las rectas $X=1, X=5, Y=2, Y=6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limites para la clase 1\n",
    "pos_x_min = 1.0\n",
    "pos_x_max = 5.0\n",
    "pos_y_min = 2.0\n",
    "pos_y_max = 6.0\n",
    "# Limites para la clase 0\n",
    "neg_x_min = 5.0\n",
    "neg_x_max = 9.0\n",
    "neg_y_min = 6.0\n",
    "neg_y_max = 9.0\n",
    "# Tamanios de clases\n",
    "sz_clase = 50\n",
    "\n",
    "# Clase 1\n",
    "X = np.random.uniform(pos_x_min, pos_x_max, (sz_clase, 1))\n",
    "Y = np.random.uniform(pos_y_min, pos_y_max, (sz_clase, 1))\n",
    "clase = np.atleast_2d(np.ones(X.shape[0]))\n",
    "clase1 = np.concatenate((clase.T, X, Y), axis=1)\n",
    "\n",
    "# Clase 0\n",
    "X = np.random.uniform(neg_x_min, neg_x_max, (sz_clase, 1))\n",
    "Y = np.random.uniform(neg_y_min, neg_y_max, (sz_clase, 1))\n",
    "clase = np.atleast_2d(np.zeros(X.shape[0]))\n",
    "clase0 = np.concatenate((clase.T, X, Y), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2\n",
    "\n",
    "Tomar aleatoriamente 80 muestras, ese será el conjunto de entrenamiento. Las otras 20 son el conjunto de prueba.Pero procurar que hayan 40 positivas y 40 negativas, así como también 10 positivas y 10 negativas. Sin repetición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos indices aleatorios para cada clase\n",
    "#(se podria usar el mismo para ambos).\n",
    "ch_clase1 = random.sample(range(sz_clase), sz_clase)\n",
    "ch_clase0 = random.sample(range(sz_clase), sz_clase)\n",
    "\n",
    "training_set = []\n",
    "test_set = []\n",
    "for i in range(sz_clase):\n",
    "    # Primero tomamos el de prueba\n",
    "    if i < 10:\n",
    "        test_set.append(clase1[ch_clase1[i]])\n",
    "        test_set.append(clase0[ch_clase0[i]])\n",
    "    else:\n",
    "        training_set.append(clase1[ch_clase1[i]])\n",
    "        training_set.append(clase0[ch_clase0[i]])\n",
    "        \n",
    "# Para comodidad\n",
    "training_set = np.array(training_set)\n",
    "test_set = np.array(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3\n",
    "\n",
    "Obtener dos redes con mínimo error de entrenamiento, y reportar el conjunto de pesos de la solución.  Mostrar las ecuaciones de las rectas que genera cada uno de los nodos del Perceptrón (utilizando los pesos y el bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3f27462610>]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_min = 0.0\n",
    "x_max = 10.0\n",
    "y_min = 0.0\n",
    "y_max = 10.0\n",
    "\n",
    "buenos = clase1[:, 1:]\n",
    "malos = clase0[:, 1:]\n",
    "\n",
    "plt.plot(buenos[:, 0], buenos[:, 1], 'go')\n",
    "plt.plot(malos[:, 0], malos[:, 1], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "X: [2.17865624 3.05341973] y: [1.] \n",
      "\tAproximacion:  [0.9983784]\n",
      "X: [7.86948967 6.41085691] y: [0.] \n",
      "\tAproximacion:  [-0.02142919]\n",
      "X: [3.58852884 4.45174689] y: [1.] \n",
      "\tAproximacion:  [0.99527414]\n",
      "X: [7.84020657 8.32714238] y: [0.] \n",
      "\tAproximacion:  [-0.02557766]\n",
      "X: [1.58341219 4.05182444] y: [1.] \n",
      "\tAproximacion:  [0.99840737]\n",
      "X: [5.48711015 7.30757957] y: [0.] \n",
      "\tAproximacion:  [0.00436285]\n",
      "X: [4.35820568 5.24378083] y: [1.] \n",
      "\tAproximacion:  [0.62653421]\n",
      "X: [6.18168175 8.00212487] y: [0.] \n",
      "\tAproximacion:  [-0.01836175]\n",
      "X: [1.45941106 5.96071583] y: [1.] \n",
      "\tAproximacion:  [0.99844708]\n",
      "\n",
      "Pesos:\n",
      "\n",
      "[[-3.50973551e+00  3.76880403e-04 -7.97165898e-01]\n",
      " [ 5.22570741e-01 -2.91189788e-01 -3.35444317e-01]\n",
      " [ 4.10991032e-01 -9.42273003e-01 -5.00701479e-01]]\n",
      "[[ 2.42666206  0.6654714  -0.17341966]\n",
      " [ 0.78168601 -0.65077532 -1.01909836]\n",
      " [ 0.50415257 -0.8653251  -0.18747264]]\n",
      "[[-2.04763863]\n",
      " [ 0.95420399]\n",
      " [ 0.91759151]]\n"
     ]
    }
   ],
   "source": [
    "nn1 = fast_training(training_set[:, 1:], training_set[:, 0:1], hiden_layers=[2,2], epochs=70001, activation='tanh')\n",
    "\n",
    "print('\\nPesos:\\n')\n",
    "for w in nn1.get_weights():\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "X: [2.17865624 3.05341973] y: [1.] \n",
      "\tAproximacion:  [0.99968129]\n",
      "X: [7.86948967 6.41085691] y: [0.] \n",
      "\tAproximacion:  [-0.03040071]\n",
      "X: [3.58852884 4.45174689] y: [1.] \n",
      "\tAproximacion:  [0.98760154]\n",
      "X: [7.84020657 8.32714238] y: [0.] \n",
      "\tAproximacion:  [-0.04279695]\n",
      "X: [1.58341219 4.05182444] y: [1.] \n",
      "\tAproximacion:  [0.99966338]\n",
      "X: [5.48711015 7.30757957] y: [0.] \n",
      "\tAproximacion:  [0.05464558]\n",
      "X: [4.35820568 5.24378083] y: [1.] \n",
      "\tAproximacion:  [0.78902491]\n",
      "X: [6.18168175 8.00212487] y: [0.] \n",
      "\tAproximacion:  [-0.01647885]\n",
      "X: [1.45941106 5.96071583] y: [1.] \n",
      "\tAproximacion:  [0.99872805]\n",
      "\n",
      "Pesos:\n",
      "\n",
      "[[-0.54759375  1.01259052  0.37719711 -3.5334388 ]\n",
      " [-0.94263264  0.16223079  0.30725672  0.51600119]\n",
      " [-0.52688217  0.55322847  0.97892963  0.35730019]]\n",
      "[[-0.77248252]\n",
      " [ 1.17711398]\n",
      " [ 0.37416819]\n",
      " [-2.37101569]]\n"
     ]
    }
   ],
   "source": [
    "nn2 = fast_training(training_set[:, 1:], training_set[:, 0:1], hiden_layers=[3], epochs=40001, activation='tanh')\n",
    "\n",
    "print('\\nPesos:\\n')\n",
    "for w in nn2.get_weights():\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4\n",
    "\n",
    "Para cada red determinar el error de validación. Para esto se presentan las muestras del conjunto de validación y se determina el error de cada muestra, y se reporta el promedio de muestras bien clasificadas entre el total de muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_hope = test_set[:, 0:1]\n",
    "input_nn = test_set[:, 1:]\n",
    "\n",
    "def validacion(nn, out_hope, input_nn, tolerancia=0.01):\n",
    "    test_out = [nn.evaluate(x) for x in input_nn]\n",
    "    error_test = np.mean(abs(test_out - out_hope))\n",
    "    print(f\"El error promedio obtenido en la red es {error_test}\")\n",
    "\n",
    "    tot = 0\n",
    "    for prb, crrc in zip(test_out, out_hope):\n",
    "        if abs(prb - crrc) < tolerancia:\n",
    "            print(f\"\\tNn:{prb} Datos:{crrc} (bien clasificada)\")\n",
    "            tot += 1\n",
    "\n",
    "    print(f\"Clasificamos {tot} bien; esto representa un {tot*100/len(out_hope)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error promedio obtenido de la primer red es 0.027941013014348447\n",
      "\tNn:[0.9984123] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.99840059] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.99850037] Datos:[1.] (bien clasificada)\n",
      "\tNn:[-0.00277411] Datos:[0.] (bien clasificada)\n",
      "\tNn:[0.99606563] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.99846917] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.99831303] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.9984507] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.99625392] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.99768475] Datos:[1.] (bien clasificada)\n",
      "Clasificamos 10 bien; esto representa un 50.0%\n"
     ]
    }
   ],
   "source": [
    "validacion(nn1, out_hope, input_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error promedio obtenido de la primer red es 0.02735802065161755\n",
      "\tNn:[0.99964804] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.99758137] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.99904444] Datos:[1.] (bien clasificada)\n",
      "\tNn:[-0.00121823] Datos:[0.] (bien clasificada)\n",
      "\tNn:[0.99260396] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.9995285] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.99973629] Datos:[1.] (bien clasificada)\n",
      "\tNn:[0.99950672] Datos:[1.] (bien clasificada)\n",
      "\tNn:[-0.00714227] Datos:[0.] (bien clasificada)\n",
      "\tNn:[0.99146774] Datos:[1.] (bien clasificada)\n",
      "\tNn:[-0.00277877] Datos:[0.] (bien clasificada)\n",
      "\tNn:[0.99545891] Datos:[1.] (bien clasificada)\n",
      "Clasificamos 12 bien; esto representa un 60.0%\n"
     ]
    }
   ],
   "source": [
    "validacion(nn2, out_hope, input_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imposible $4*4$ con A\\*\n",
    "\n",
    "Trabajando ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
